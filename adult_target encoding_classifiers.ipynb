{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a156788b-4156-4892-9407-f6ff073e1e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: LR\n",
      "Accuracy: 0.844 (95% CI: 0.841 - 0.847)\n",
      "Precision: 0.739 (95% CI: 0.730 - 0.747)\n",
      "Recall: 0.572 (95% CI: 0.562 - 0.581)\n",
      "F1 Score: 0.644 (95% CI: 0.637 - 0.652)\n",
      "ROC AUC: 0.899 (95% CI: 0.895 - 0.902)\n",
      "Total Computation Time: 7.731 seconds\n",
      "\n",
      "Classifier: DT\n",
      "Accuracy: 0.840 (95% CI: 0.838 - 0.843)\n",
      "Precision: 0.770 (95% CI: 0.763 - 0.777)\n",
      "Recall: 0.508 (95% CI: 0.496 - 0.521)\n",
      "F1 Score: 0.612 (95% CI: 0.602 - 0.621)\n",
      "ROC AUC: 0.861 (95% CI: 0.857 - 0.865)\n",
      "Total Computation Time: 8.595 seconds\n",
      "\n",
      "Classifier: RF\n",
      "Accuracy: 0.852 (95% CI: 0.848 - 0.855)\n",
      "Precision: 0.813 (95% CI: 0.804 - 0.822)\n",
      "Recall: 0.521 (95% CI: 0.510 - 0.532)\n",
      "F1 Score: 0.635 (95% CI: 0.626 - 0.644)\n",
      "ROC AUC: 0.906 (95% CI: 0.903 - 0.910)\n",
      "Total Computation Time: 84.797 seconds\n",
      "\n",
      "Classifier: KNN\n",
      "Accuracy: 0.823 (95% CI: 0.819 - 0.828)\n",
      "Precision: 0.657 (95% CI: 0.648 - 0.666)\n",
      "Recall: 0.603 (95% CI: 0.590 - 0.616)\n",
      "F1 Score: 0.629 (95% CI: 0.618 - 0.639)\n",
      "ROC AUC: 0.830 (95% CI: 0.823 - 0.837)\n",
      "Total Computation Time: 74.710 seconds\n",
      "\n",
      "Classifier: XGB\n",
      "Accuracy: 0.869 (95% CI: 0.865 - 0.873)\n",
      "Precision: 0.777 (95% CI: 0.768 - 0.786)\n",
      "Recall: 0.663 (95% CI: 0.652 - 0.674)\n",
      "F1 Score: 0.715 (95% CI: 0.706 - 0.724)\n",
      "ROC AUC: 0.927 (95% CI: 0.924 - 0.930)\n",
      "Total Computation Time: 14.610 seconds\n",
      "\n",
      "Classifier: MLP\n",
      "Accuracy: 0.850 (95% CI: 0.846 - 0.854)\n",
      "Precision: 0.740 (95% CI: 0.730 - 0.750)\n",
      "Recall: 0.610 (95% CI: 0.591 - 0.629)\n",
      "F1 Score: 0.668 (95% CI: 0.657 - 0.679)\n",
      "ROC AUC: 0.908 (95% CI: 0.904 - 0.911)\n",
      "Total Computation Time: 1810.718 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add confidence interval\n",
    "import config_cat_embedding\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
    "                             f1_score, roc_auc_score)\n",
    "from scipy import stats\n",
    "\n",
    "from data_prep import bank_data_prep, adult_data_prep\n",
    "from embedding_helper import create_network\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Load and preprocess data\n",
    "data_path = config_cat_embedding.paths['data']\n",
    "bank_data = pd.read_csv(data_path+'adult.csv', sep=',')\n",
    "\n",
    "df_bank, cat_cols = adult_data_prep(bank_data)\n",
    "\n",
    "X = df_bank.iloc[:, :-1]\n",
    "y = df_bank.y\n",
    "\n",
    "# Define the classifiers\n",
    "seed = 42\n",
    "# We will determine the number_of_features inside the cross-validation loop after preprocessing\n",
    "\n",
    "models = [\n",
    "    ('LR', LogisticRegression(solver='lbfgs', random_state=seed, max_iter=1000)),\n",
    "    ('DT', DecisionTreeClassifier(criterion='entropy', max_depth=3, random_state=seed)),\n",
    "    ('RF', RandomForestClassifier(n_estimators=200, max_depth=5, random_state=seed, min_samples_leaf=3)),\n",
    "    ('KNN', KNeighborsClassifier(n_neighbors=3)),\n",
    "    ('XGB', XGBClassifier(eval_metric='logloss', random_state=seed)),\n",
    "    # ('SVM', SVC(gamma='scale', random_state=seed, probability=True)),\n",
    "    ('MLP', KerasClassifier(\n",
    "        model=create_network,\n",
    "        epochs=100, batch_size=100, verbose=0, random_state=seed))\n",
    "]\n",
    "\n",
    "# Cross-validation setup\n",
    "cv = StratifiedKFold(n_splits=20, shuffle=True, random_state=seed)\n",
    "\n",
    "# Function to calculate confidence intervals\n",
    "def confidence_interval(data, confidence=0.95):\n",
    "    n = len(data)\n",
    "    m = np.mean(data)\n",
    "    std_err = stats.sem(data)\n",
    "    h = std_err * stats.t.ppf((1 + confidence) / 2, n - 1)\n",
    "    return m, m - h, m + h\n",
    "\n",
    "# Loop over models\n",
    "for name, model in models:\n",
    "    print(f\"Classifier: {name}\")\n",
    "    # Lists to store metrics for each fold\n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1s = []\n",
    "    roc_aucs = []\n",
    "    \n",
    "    # Start the timer before cross-validation\n",
    "    start_time = time.time()\n",
    "    \n",
    "    fold = 1\n",
    "    for train_index, test_index in cv.split(X, y):\n",
    "        # Split the data into training and testing sets for this fold\n",
    "        X_train_fold, X_test_fold = X.iloc[train_index].copy(), X.iloc[test_index].copy()\n",
    "        y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        # Preprocess data within the fold\n",
    "        # Target encoding\n",
    "        import category_encoders as ce\n",
    "        target_encoder = ce.TargetEncoder(cols=cat_cols, smoothing=1)\n",
    "        X_train_enc = target_encoder.fit_transform(X_train_fold, y_train_fold)\n",
    "        X_test_enc = target_encoder.transform(X_test_fold)\n",
    "        \n",
    "        # Standard scaling\n",
    "        stc = StandardScaler()\n",
    "        X_train_scaled = stc.fit_transform(X_train_enc)\n",
    "        X_test_scaled = stc.transform(X_test_enc)\n",
    "        \n",
    "        # Update number_of_features for MLP\n",
    "        number_of_features = X_train_scaled.shape[1]\n",
    "        if name == 'MLP':\n",
    "            # Update the model with the correct number of features\n",
    "            model.set_params(model__number_of_features=number_of_features)\n",
    "        \n",
    "        # Fit the model\n",
    "        model.fit(X_train_scaled, y_train_fold)\n",
    "        # Predict on the test fold\n",
    "        y_pred_fold = model.predict(X_test_scaled)\n",
    "        \n",
    "        # Get prediction probabilities for ROC AUC\n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            y_pred_prob_fold = model.predict_proba(X_test_scaled)[:, 1]\n",
    "        else:\n",
    "            # For classifiers without predict_proba, use decision_function\n",
    "            y_pred_prob_fold = model.decision_function(X_test_scaled)\n",
    "            # Normalize the decision function output to [0,1] range\n",
    "            y_pred_prob_fold = (y_pred_prob_fold - y_pred_prob_fold.min()) / (y_pred_prob_fold.max() - y_pred_prob_fold.min())\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracies.append(accuracy_score(y_test_fold, y_pred_fold))\n",
    "        precisions.append(precision_score(y_test_fold, y_pred_fold, zero_division=0))\n",
    "        recalls.append(recall_score(y_test_fold, y_pred_fold))\n",
    "        f1s.append(f1_score(y_test_fold, y_pred_fold))\n",
    "        roc_aucs.append(roc_auc_score(y_test_fold, y_pred_prob_fold))\n",
    "        \n",
    "        # print(f\"Fold {fold} completed.\")\n",
    "        fold += 1\n",
    "    \n",
    "    # Stop the timer after cross-validation\n",
    "    end_time = time.time()\n",
    "    total_computation_time = end_time - start_time  # Total time for the model\n",
    "    \n",
    "    # Calculate mean and confidence intervals\n",
    "    acc_mean, acc_ci_lower, acc_ci_upper = confidence_interval(accuracies)\n",
    "    prec_mean, prec_ci_lower, prec_ci_upper = confidence_interval(precisions)\n",
    "    rec_mean, rec_ci_lower, rec_ci_upper = confidence_interval(recalls)\n",
    "    f1_mean, f1_ci_lower, f1_ci_upper = confidence_interval(f1s)\n",
    "    roc_mean, roc_ci_lower, roc_ci_upper = confidence_interval(roc_aucs)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"Accuracy: {acc_mean:.3f} (95% CI: {acc_ci_lower:.3f} - {acc_ci_upper:.3f})\")\n",
    "    print(f\"Precision: {prec_mean:.3f} (95% CI: {prec_ci_lower:.3f} - {prec_ci_upper:.3f})\")\n",
    "    print(f\"Recall: {rec_mean:.3f} (95% CI: {rec_ci_lower:.3f} - {rec_ci_upper:.3f})\")\n",
    "    print(f\"F1 Score: {f1_mean:.3f} (95% CI: {f1_ci_lower:.3f} - {f1_ci_upper:.3f})\")\n",
    "    print(f\"ROC AUC: {roc_mean:.3f} (95% CI: {roc_ci_lower:.3f} - {roc_ci_upper:.3f})\")\n",
    "    print(f\"Total Computation Time: {total_computation_time:.3f} seconds\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
