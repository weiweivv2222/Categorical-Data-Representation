{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec58a0da-b73f-49d6-8097-03c4c3673b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: LR\n",
      "Accuracy: 0.907 (95% CI: 0.905 - 0.910)\n",
      "Precision: 0.663 (95% CI: 0.642 - 0.684)\n",
      "Recall: 0.362 (95% CI: 0.343 - 0.381)\n",
      "F1 Score: 0.468 (95% CI: 0.449 - 0.487)\n",
      "ROC AUC: 0.914 (95% CI: 0.909 - 0.919)\n",
      "Total Computation Time: 20.617 seconds\n",
      "\n",
      "Classifier: DT\n",
      "Accuracy: 0.906 (95% CI: 0.904 - 0.908)\n",
      "Precision: 0.650 (95% CI: 0.632 - 0.668)\n",
      "Recall: 0.358 (95% CI: 0.342 - 0.374)\n",
      "F1 Score: 0.461 (95% CI: 0.445 - 0.478)\n",
      "ROC AUC: 0.842 (95% CI: 0.835 - 0.849)\n",
      "Total Computation Time: 19.705 seconds\n",
      "\n",
      "Classifier: RF\n",
      "Accuracy: 0.901 (95% CI: 0.900 - 0.903)\n",
      "Precision: 0.782 (95% CI: 0.758 - 0.805)\n",
      "Recall: 0.171 (95% CI: 0.155 - 0.187)\n",
      "F1 Score: 0.279 (95% CI: 0.257 - 0.301)\n",
      "ROC AUC: 0.907 (95% CI: 0.901 - 0.912)\n",
      "Total Computation Time: 80.550 seconds\n",
      "\n",
      "Classifier: KNN\n",
      "Accuracy: 0.891 (95% CI: 0.889 - 0.893)\n",
      "Precision: 0.527 (95% CI: 0.509 - 0.544)\n",
      "Recall: 0.305 (95% CI: 0.289 - 0.321)\n",
      "F1 Score: 0.386 (95% CI: 0.369 - 0.403)\n",
      "ROC AUC: 0.743 (95% CI: 0.734 - 0.752)\n",
      "Total Computation Time: 31.353 seconds\n",
      "\n",
      "Classifier: XGB\n",
      "Accuracy: 0.908 (95% CI: 0.906 - 0.911)\n",
      "Precision: 0.622 (95% CI: 0.607 - 0.637)\n",
      "Recall: 0.476 (95% CI: 0.456 - 0.496)\n",
      "F1 Score: 0.539 (95% CI: 0.522 - 0.555)\n",
      "ROC AUC: 0.928 (95% CI: 0.925 - 0.932)\n",
      "Total Computation Time: 34.673 seconds\n",
      "\n",
      "Classifier: MLP\n",
      "Accuracy: 0.895 (95% CI: 0.892 - 0.898)\n",
      "Precision: 0.544 (95% CI: 0.526 - 0.561)\n",
      "Recall: 0.452 (95% CI: 0.433 - 0.471)\n",
      "F1 Score: 0.492 (95% CI: 0.479 - 0.504)\n",
      "ROC AUC: 0.901 (95% CI: 0.897 - 0.906)\n",
      "Total Computation Time: 1462.534 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#add confident interval\n",
    "import config_cat_embedding\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
    "                             f1_score, roc_auc_score)\n",
    "from scipy import stats\n",
    "\n",
    "from data_prep import bank_data_prep, adult_data_prep\n",
    "from embedding_helper import create_network\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Load and preprocess data\n",
    "data_path = config_cat_embedding.paths['data']\n",
    "bank_data = pd.read_csv(data_path + 'bank-additional-full.csv', sep=';')\n",
    "\n",
    "df_bank, cat_cols = bank_data_prep(bank_data)\n",
    "\n",
    "X = df_bank.iloc[:, :-1]\n",
    "y = df_bank.y\n",
    "\n",
    "# Define the classifiers\n",
    "seed = 42\n",
    "# We will determine the number_of_features inside the cross-validation loop after preprocessing\n",
    "\n",
    "models = [\n",
    "    ('LR', LogisticRegression(solver='lbfgs', random_state=seed, max_iter=1000)),\n",
    "    ('DT', DecisionTreeClassifier(criterion='entropy', max_depth=3, random_state=seed)),\n",
    "    ('RF', RandomForestClassifier(n_estimators=200, max_depth=5, random_state=seed, min_samples_leaf=3)),\n",
    "    ('KNN', KNeighborsClassifier(n_neighbors=3)),\n",
    "    ('XGB', XGBClassifier(eval_metric='logloss', random_state=seed)),\n",
    "    # ('SVM', SVC(gamma='scale', random_state=seed, probability=True)),\n",
    "    ('MLP', KerasClassifier(\n",
    "        model=create_network,\n",
    "        epochs=100, batch_size=100, verbose=0, random_state=seed))\n",
    "]\n",
    "\n",
    "# Cross-validation setup\n",
    "cv = StratifiedKFold(n_splits=20, shuffle=True, random_state=seed)\n",
    "\n",
    "# Function to calculate confidence intervals\n",
    "def confidence_interval(data, confidence=0.95):\n",
    "    n = len(data)\n",
    "    m = np.mean(data)\n",
    "    std_err = stats.sem(data)\n",
    "    h = std_err * stats.t.ppf((1 + confidence) / 2, n - 1)\n",
    "    return m, m - h, m + h\n",
    "\n",
    "# Loop over models\n",
    "for name, model in models:\n",
    "    print(f\"Classifier: {name}\")\n",
    "    # Lists to store metrics for each fold\n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1s = []\n",
    "    roc_aucs = []\n",
    "    \n",
    "    # Start the timer before cross-validation\n",
    "    start_time = time.time()\n",
    "    \n",
    "    fold = 1\n",
    "    for train_index, test_index in cv.split(X, y):\n",
    "        # Split the data into training and testing sets for this fold\n",
    "        X_train_fold, X_test_fold = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        # Preprocess data within the fold\n",
    "        # One-hot encoding\n",
    "        import category_encoders as ce\n",
    "        one_hot_encoder = ce.OneHotEncoder(cols=cat_cols)\n",
    "        X_train_ohe = one_hot_encoder.fit_transform(X_train_fold)\n",
    "        X_test_ohe = one_hot_encoder.transform(X_test_fold)\n",
    "        \n",
    "        # Standard scaling\n",
    "        stc = StandardScaler()\n",
    "        X_train_scaled = stc.fit_transform(X_train_ohe)\n",
    "        X_test_scaled = stc.transform(X_test_ohe)\n",
    "        \n",
    "        # Update number_of_features for MLP\n",
    "        number_of_features = X_train_scaled.shape[1]\n",
    "        if name == 'MLP':\n",
    "            # Update the model with the correct number of features\n",
    "            model.set_params(model__number_of_features=number_of_features)\n",
    "        \n",
    "        # Fit the model\n",
    "        model.fit(X_train_scaled, y_train_fold)\n",
    "        # Predict on the test fold\n",
    "        y_pred_fold = model.predict(X_test_scaled)\n",
    "        \n",
    "        # Get prediction probabilities for ROC AUC\n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            y_pred_prob_fold = model.predict_proba(X_test_scaled)[:, 1]\n",
    "        else:\n",
    "            # For classifiers without predict_proba, use decision_function\n",
    "            y_pred_prob_fold = model.decision_function(X_test_scaled)\n",
    "            # Normalize the decision function output to [0,1] range\n",
    "            y_pred_prob_fold = (y_pred_prob_fold - y_pred_prob_fold.min()) / (y_pred_prob_fold.max() - y_pred_prob_fold.min())\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracies.append(accuracy_score(y_test_fold, y_pred_fold))\n",
    "        precisions.append(precision_score(y_test_fold, y_pred_fold, zero_division=0))\n",
    "        recalls.append(recall_score(y_test_fold, y_pred_fold))\n",
    "        f1s.append(f1_score(y_test_fold, y_pred_fold))\n",
    "        roc_aucs.append(roc_auc_score(y_test_fold, y_pred_prob_fold))\n",
    "        \n",
    "       # print(f\"Fold {fold} completed.\")\n",
    "        fold += 1\n",
    "    \n",
    "    # Stop the timer after cross-validation\n",
    "    end_time = time.time()\n",
    "    total_computation_time = end_time - start_time  # Total time for the model\n",
    "    \n",
    "    # Calculate mean and confidence intervals\n",
    "    acc_mean, acc_ci_lower, acc_ci_upper = confidence_interval(accuracies)\n",
    "    prec_mean, prec_ci_lower, prec_ci_upper = confidence_interval(precisions)\n",
    "    rec_mean, rec_ci_lower, rec_ci_upper = confidence_interval(recalls)\n",
    "    f1_mean, f1_ci_lower, f1_ci_upper = confidence_interval(f1s)\n",
    "    roc_mean, roc_ci_lower, roc_ci_upper = confidence_interval(roc_aucs)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"Accuracy: {acc_mean:.3f} (95% CI: {acc_ci_lower:.3f} - {acc_ci_upper:.3f})\")\n",
    "    print(f\"Precision: {prec_mean:.3f} (95% CI: {prec_ci_lower:.3f} - {prec_ci_upper:.3f})\")\n",
    "    print(f\"Recall: {rec_mean:.3f} (95% CI: {rec_ci_lower:.3f} - {rec_ci_upper:.3f})\")\n",
    "    print(f\"F1 Score: {f1_mean:.3f} (95% CI: {f1_ci_lower:.3f} - {f1_ci_upper:.3f})\")\n",
    "    print(f\"ROC AUC: {roc_mean:.3f} (95% CI: {roc_ci_lower:.3f} - {roc_ci_upper:.3f})\")\n",
    "    print(f\"Total Computation Time: {total_computation_time:.3f} seconds\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
