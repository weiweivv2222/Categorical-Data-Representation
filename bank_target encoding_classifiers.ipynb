{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61dcc8b1-df85-4af4-983a-7fc6af4ce7fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: LR\n",
      "Accuracy: 0.907 (95% CI: 0.905 - 0.909)\n",
      "Precision: 0.661 (95% CI: 0.644 - 0.679)\n",
      "Recall: 0.352 (95% CI: 0.335 - 0.368)\n",
      "F1 Score: 0.458 (95% CI: 0.442 - 0.475)\n",
      "ROC AUC: 0.913 (95% CI: 0.909 - 0.917)\n",
      "Total Computation Time: 6.577 seconds\n",
      "\n",
      "Classifier: DT\n",
      "Accuracy: 0.906 (95% CI: 0.904 - 0.908)\n",
      "Precision: 0.650 (95% CI: 0.632 - 0.668)\n",
      "Recall: 0.358 (95% CI: 0.342 - 0.374)\n",
      "F1 Score: 0.461 (95% CI: 0.445 - 0.478)\n",
      "ROC AUC: 0.850 (95% CI: 0.844 - 0.857)\n",
      "Total Computation Time: 6.031 seconds\n",
      "\n",
      "Classifier: RF\n",
      "Accuracy: 0.902 (95% CI: 0.900 - 0.903)\n",
      "Precision: 0.757 (95% CI: 0.733 - 0.781)\n",
      "Recall: 0.187 (95% CI: 0.171 - 0.203)\n",
      "F1 Score: 0.299 (95% CI: 0.278 - 0.320)\n",
      "ROC AUC: 0.912 (95% CI: 0.907 - 0.917)\n",
      "Total Computation Time: 52.642 seconds\n",
      "\n",
      "Classifier: KNN\n",
      "Accuracy: 0.892 (95% CI: 0.890 - 0.895)\n",
      "Precision: 0.529 (95% CI: 0.514 - 0.543)\n",
      "Recall: 0.395 (95% CI: 0.377 - 0.412)\n",
      "F1 Score: 0.451 (95% CI: 0.435 - 0.468)\n",
      "ROC AUC: 0.789 (95% CI: 0.781 - 0.797)\n",
      "Total Computation Time: 32.846 seconds\n",
      "\n",
      "Classifier: XGB\n",
      "Accuracy: 0.910 (95% CI: 0.906 - 0.913)\n",
      "Precision: 0.629 (95% CI: 0.611 - 0.647)\n",
      "Recall: 0.481 (95% CI: 0.461 - 0.502)\n",
      "F1 Score: 0.545 (95% CI: 0.526 - 0.564)\n",
      "ROC AUC: 0.928 (95% CI: 0.924 - 0.931)\n",
      "Total Computation Time: 16.080 seconds\n",
      "\n",
      "Classifier: MLP\n",
      "Accuracy: 0.904 (95% CI: 0.901 - 0.907)\n",
      "Precision: 0.600 (95% CI: 0.579 - 0.621)\n",
      "Recall: 0.447 (95% CI: 0.423 - 0.471)\n",
      "F1 Score: 0.511 (95% CI: 0.492 - 0.529)\n",
      "ROC AUC: 0.913 (95% CI: 0.909 - 0.917)\n",
      "Total Computation Time: 1640.136 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add confidence interval\n",
    "import config_cat_embedding\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
    "                             f1_score, roc_auc_score)\n",
    "from scipy import stats\n",
    "\n",
    "from data_prep import bank_data_prep, adult_data_prep\n",
    "from embedding_helper import create_network\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Load and preprocess data\n",
    "data_path = config_cat_embedding.paths['data']\n",
    "bank_data = pd.read_csv(data_path + 'bank-additional-full.csv', sep=';')\n",
    "\n",
    "df_bank, cat_cols = bank_data_prep(bank_data)\n",
    "\n",
    "X = df_bank.iloc[:, :-1]\n",
    "y = df_bank.y\n",
    "\n",
    "# Define the classifiers\n",
    "seed = 42\n",
    "# We will determine the number_of_features inside the cross-validation loop after preprocessing\n",
    "\n",
    "models = [\n",
    "    ('LR', LogisticRegression(solver='lbfgs', random_state=seed, max_iter=1000)),\n",
    "    ('DT', DecisionTreeClassifier(criterion='entropy', max_depth=3, random_state=seed)),\n",
    "    ('RF', RandomForestClassifier(n_estimators=200, max_depth=5, random_state=seed, min_samples_leaf=3)),\n",
    "    ('KNN', KNeighborsClassifier(n_neighbors=3)),\n",
    "    ('XGB', XGBClassifier(eval_metric='logloss', random_state=seed)),\n",
    "    # ('SVM', SVC(gamma='scale', random_state=seed, probability=True)),\n",
    "    ('MLP', KerasClassifier(\n",
    "        model=create_network,\n",
    "        epochs=100, batch_size=100, verbose=0, random_state=seed))\n",
    "]\n",
    "\n",
    "# Cross-validation setup\n",
    "cv = StratifiedKFold(n_splits=20, shuffle=True, random_state=seed)\n",
    "\n",
    "# Function to calculate confidence intervals\n",
    "def confidence_interval(data, confidence=0.95):\n",
    "    n = len(data)\n",
    "    m = np.mean(data)\n",
    "    std_err = stats.sem(data)\n",
    "    h = std_err * stats.t.ppf((1 + confidence) / 2, n - 1)\n",
    "    return m, m - h, m + h\n",
    "\n",
    "# Loop over models\n",
    "for name, model in models:\n",
    "    print(f\"Classifier: {name}\")\n",
    "    # Lists to store metrics for each fold\n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1s = []\n",
    "    roc_aucs = []\n",
    "    \n",
    "    # Start the timer before cross-validation\n",
    "    start_time = time.time()\n",
    "    \n",
    "    fold = 1\n",
    "    for train_index, test_index in cv.split(X, y):\n",
    "        # Split the data into training and testing sets for this fold\n",
    "        X_train_fold, X_test_fold = X.iloc[train_index].copy(), X.iloc[test_index].copy()\n",
    "        y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        # Preprocess data within the fold\n",
    "        # Target encoding\n",
    "        import category_encoders as ce\n",
    "        target_encoder = ce.TargetEncoder(cols=cat_cols, smoothing=1)\n",
    "        X_train_enc = target_encoder.fit_transform(X_train_fold, y_train_fold)\n",
    "        X_test_enc = target_encoder.transform(X_test_fold)\n",
    "        \n",
    "        # Standard scaling\n",
    "        stc = StandardScaler()\n",
    "        X_train_scaled = stc.fit_transform(X_train_enc)\n",
    "        X_test_scaled = stc.transform(X_test_enc)\n",
    "        \n",
    "        # Update number_of_features for MLP\n",
    "        number_of_features = X_train_scaled.shape[1]\n",
    "        if name == 'MLP':\n",
    "            # Update the model with the correct number of features\n",
    "            model.set_params(model__number_of_features=number_of_features)\n",
    "        \n",
    "        # Fit the model\n",
    "        model.fit(X_train_scaled, y_train_fold)\n",
    "        # Predict on the test fold\n",
    "        y_pred_fold = model.predict(X_test_scaled)\n",
    "        \n",
    "        # Get prediction probabilities for ROC AUC\n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            y_pred_prob_fold = model.predict_proba(X_test_scaled)[:, 1]\n",
    "        else:\n",
    "            # For classifiers without predict_proba, use decision_function\n",
    "            y_pred_prob_fold = model.decision_function(X_test_scaled)\n",
    "            # Normalize the decision function output to [0,1] range\n",
    "            y_pred_prob_fold = (y_pred_prob_fold - y_pred_prob_fold.min()) / (y_pred_prob_fold.max() - y_pred_prob_fold.min())\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracies.append(accuracy_score(y_test_fold, y_pred_fold))\n",
    "        precisions.append(precision_score(y_test_fold, y_pred_fold, zero_division=0))\n",
    "        recalls.append(recall_score(y_test_fold, y_pred_fold))\n",
    "        f1s.append(f1_score(y_test_fold, y_pred_fold))\n",
    "        roc_aucs.append(roc_auc_score(y_test_fold, y_pred_prob_fold))\n",
    "        \n",
    "        # print(f\"Fold {fold} completed.\")\n",
    "        fold += 1\n",
    "    \n",
    "    # Stop the timer after cross-validation\n",
    "    end_time = time.time()\n",
    "    total_computation_time = end_time - start_time  # Total time for the model\n",
    "    \n",
    "    # Calculate mean and confidence intervals\n",
    "    acc_mean, acc_ci_lower, acc_ci_upper = confidence_interval(accuracies)\n",
    "    prec_mean, prec_ci_lower, prec_ci_upper = confidence_interval(precisions)\n",
    "    rec_mean, rec_ci_lower, rec_ci_upper = confidence_interval(recalls)\n",
    "    f1_mean, f1_ci_lower, f1_ci_upper = confidence_interval(f1s)\n",
    "    roc_mean, roc_ci_lower, roc_ci_upper = confidence_interval(roc_aucs)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"Accuracy: {acc_mean:.3f} (95% CI: {acc_ci_lower:.3f} - {acc_ci_upper:.3f})\")\n",
    "    print(f\"Precision: {prec_mean:.3f} (95% CI: {prec_ci_lower:.3f} - {prec_ci_upper:.3f})\")\n",
    "    print(f\"Recall: {rec_mean:.3f} (95% CI: {rec_ci_lower:.3f} - {rec_ci_upper:.3f})\")\n",
    "    print(f\"F1 Score: {f1_mean:.3f} (95% CI: {f1_ci_lower:.3f} - {f1_ci_upper:.3f})\")\n",
    "    print(f\"ROC AUC: {roc_mean:.3f} (95% CI: {roc_ci_lower:.3f} - {roc_ci_upper:.3f})\")\n",
    "    print(f\"Total Computation Time: {total_computation_time:.3f} seconds\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
